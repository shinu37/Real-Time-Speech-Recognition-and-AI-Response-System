{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c6210a-59a5-4e0e-afcc-8b71e649f4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\shinu\\anaconda3\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: speechrecognition in c:\\users\\shinu\\anaconda3\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\shinu\\anaconda3\\lib\\site-packages (from speechrecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\shinu\\anaconda3\\lib\\site-packages (from speechrecognition) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shinu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shinu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shinu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shinu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->speechrecognition) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio speechrecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb006a8-0d5b-41ad-833c-25c0e33c86d4",
   "metadata": {},
   "source": [
    "**1. Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fdb95eb-2cc8-41d8-9584-ef8cf1e41641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pyaudio\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "import threading\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a7711-9acb-470d-90ea-06e839752ef2",
   "metadata": {},
   "source": [
    "**2. Taking in Inputs with PyAudio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2716f562-79e4-4395-a461-e362a1859ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_file = \"audio_input.wav\"\n",
    "video_file = \"webcam_output.avi\"\n",
    "response_audio = \"response.mp3\"\n",
    "transcription_text = \"\"\n",
    "response_text = \"\"\n",
    "\n",
    "def record_audio_with_pyaudio(start_event, filename=\"audio_input.wav\", duration=10, rate=16000, channels=1):\n",
    "    print(\"Waiting for video initialization...\")\n",
    "    start_event.wait() \n",
    "    print(\"Starting audio recording...\")\n",
    "\n",
    "    chunk = 1024\n",
    "    format = pyaudio.paInt16\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=format,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk)\n",
    "    \n",
    "    frames = []\n",
    "    for _ in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "    \n",
    "    print(\"Audio recording complete.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(frames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e014a4-441c-4d9d-986e-3b54075d2947",
   "metadata": {},
   "source": [
    "**3. Taking video input with the help of OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ce902bb-c4fa-47b9-b831-8329c4602bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to capture video from the webcam\n",
    "def record_webcam_video(start_event, output_file=\"webcam_output.avi\", duration=10):\n",
    "    print(\"Accessing webcam...\")\n",
    "    cap = cv2.VideoCapture(0)  \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS)) or 30  \n",
    "\n",
    "    out = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*'XVID'), frame_rate, (frame_width, frame_height))\n",
    "\n",
    "    \n",
    "    start_event.set()  # Signal audio recording to start\n",
    "    print(\"Starting video recording...\")\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened() and frame_count < frame_rate * duration:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to capture video.\")\n",
    "            break\n",
    "        out.write(frame)  # Save the frame to file\n",
    "        cv2.imshow(\"Webcam Feed\", frame)\n",
    "        frame_count += 1\n",
    "\n",
    "        # Break on 'q' key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Video recording complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6041cce2-de33-4d98-b541-e810c1d0bcdd",
   "metadata": {},
   "source": [
    "**4. Transcribing text with the help of SpeechRecognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0442017-96e0-476c-86cf-b86e52c68197",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transcribe_audio():\n",
    "    global transcription_text\n",
    "    recognizer = sr.Recognizer()\n",
    "    print(\"Transcribing audio...\")\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "        try:\n",
    "            transcription_text = recognizer.recognize_google(audio)\n",
    "            print(\"Transcription:\", transcription_text)\n",
    "        except sr.UnknownValueError:\n",
    "            transcription_text = \"Sorry, I couldn't understand the audio.\"\n",
    "        except sr.RequestError as e:\n",
    "            transcription_text = f\"Speech recognition service error: {e}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25924305-2f8f-48a3-bd2a-1217037b3696",
   "metadata": {},
   "source": [
    "**5. Using a hosted ChatGPT 3.5 turbo model to get an output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b632c597-8d81-4431-b100-c25592994ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"pk-dkpqgLnxgaoyhIGlDUOWbqSFwzqdVWygiNDpFvSMRmvukeUh\"  \n",
    "openai.api_base = \"https://api.pawan.krd/cosmosrp/v1/\"\n",
    "\n",
    "# Function to generate a response using OpenAI's API\n",
    "def generate_response(prompt):\n",
    "    print(\"Generating response from AI...\")\n",
    "    try:\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a straightforward assistant who says concise answers without mentioning your tone or action \"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        generated_text = completion.choices[0].message.content\n",
    "        print(\"Generated Response:\", generated_text)\n",
    "        return generated_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return \"I'm sorry, I couldn't generate a response.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff188f84-71cd-4822-b989-97f77cbc9268",
   "metadata": {},
   "source": [
    "**6. Using pyttsx3 for text to speech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e1f439-b7d5-4633-8123-41c304f2b68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# **Function to convert text to speech using pyttsx3**\n",
    "def text_to_speech(text):\n",
    "    print(\"Converting text to speech...\")\n",
    "    try:\n",
    "        # Initialize the pyttsx3 engine\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty('rate', 150)            # Set speech speed\n",
    "        engine.setProperty('volume', 0.9)                # Set volume (0.0 to 1.0)\n",
    "        engine.say(text)                        # Queue the text for speech\n",
    "        engine.runAndWait()                  # Run the speech engine\n",
    "        print(\"Speech playback started.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in text-to-speech conversion: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022bde5c-fb31-4ff7-a1c9-96a79934d645",
   "metadata": {},
   "source": [
    "**7. Main Program**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e2e3b3f-2174-4f37-a9af-fa433e58d24b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing webcam...\n",
      "Waiting for video initialization...\n",
      "Starting video recording...Starting audio recording...\n",
      "\n",
      "Video recording complete.\n",
      "Audio recording complete.\n",
      "Transcribing audio...\n",
      "Transcription: what is the capital of Kerala\n",
      "\n",
      "Final Transcription: what is the capital of Kerala\n",
      "Generating response from AI...\n",
      "Generated Response: *Thiruvananthapuram is the capital of Kerala.*\n",
      "\n",
      "Generated AI Response: *Thiruvananthapuram is the capital of Kerala.*\n",
      "Converting text to speech...\n",
      "Speech playback started.\n",
      "\n",
      "Audio, Video, and Response Processing Completed Successfully.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    duration = 10  # Duration for synchronized recording\n",
    "\n",
    "    # Event to synchronize audio and video start\n",
    "    start_event = threading.Event()\n",
    "\n",
    "    # Start audio and video recording threads\n",
    "    audio_thread = threading.Thread(target=record_audio_with_pyaudio, args=(start_event, \"audio_input.wav\", duration))\n",
    "    video_thread = threading.Thread(target=record_webcam_video, args=(start_event, \"webcam_output.avi\", duration))\n",
    "\n",
    "    video_thread.start()  # Start video recording (includes camera initialization)\n",
    "    audio_thread.start()  # Audio waits for the camera to be ready\n",
    "\n",
    "    video_thread.join()\n",
    "    audio_thread.join()\n",
    "\n",
    "    # Transcribe the audio\n",
    "    transcribe_audio()  # Use the function you defined\n",
    "    if transcription_text:\n",
    "        print(\"\\nFinal Transcription:\", transcription_text)\n",
    "\n",
    "        # Generate response from transcription\n",
    "        response_text = generate_response(transcription_text)\n",
    "        if response_text:\n",
    "            print(\"\\nGenerated AI Response:\", response_text)\n",
    "\n",
    "            # Convert generated response to speech\n",
    "            text_to_speech(response_text)\n",
    "\n",
    "    print(\"\\nAudio, Video, and Response Processing Completed Successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
